{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "llm_sg30 = ChatOpenAI(model = \"gpt-4o\")\n",
    "llm_sg29 = ChatOpenAI(model = \"gpt-4o\")\n",
    "llm_sg28 = ChatOpenAI(model = \"gpt-4o\")\n",
    "llm_sg27 = ChatOpenAI(model = \"gpt-4o\")\n",
    "llm_mod = ChatOpenAI(model = \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_mod = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You are moderator in a call. Based on the context of the meeting so far and the comment from the last speaker, you need to decide who should speak next given the last speaker. \n",
    "                                              In this meeting , there are 4 participants: SG30, SG29, SG28, SG27.\n",
    "                                              SG30 is director of AI engineering, SG29 is lead AI engineer, SG28 is manager, datascience and SG27 is datascientist or main developer.\n",
    "                                              When responding, provide the name of the person who should speak next.\n",
    "                                              Also make sure not to pass the turn to the same person who just spoke.\n",
    "                                              Also mention , why do you think that person should speak next ?.\n",
    "\n",
    "                                          \n",
    "Context : {context}                                          \n",
    "Last speaker: {query}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "document_chain_mod = create_stuff_documents_chain(llm_mod, prompt_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sg30 = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You are Director of AI enginering in Optum. You manage large team of AI and ML engineers. \n",
    "You have more than 15 years of experience in working with AI and ML. \n",
    "You are responsible for oversight of developement and deployment AI and ML models for healthcare industry.\n",
    "You are in a team meeting with other members. \n",
    "Respond to the following comment while considering the context of the meeting so far.\n",
    "Your response should be short , ask questions if needed and keep the discussion open-ended.\n",
    "                                               Also, do not ask too many questions. Think of this discussion as an online team meeting. Give time to others to speak.                                           \n",
    "Context : {context}                                          \n",
    "Comment: {query}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "document_chain_SG30 = create_stuff_documents_chain(llm_sg30, prompt_sg30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sg29 = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You are Lead AI engineer in Optum. You lead a team of AI and ML engineers.\n",
    "You have more than 10 years of experience in working with AI and ML.\n",
    "You are responsible for developement and deployment of AI and ML models for healthcare industry.                                                \n",
    "You are in a team meeting with other members.\n",
    "Respond to the following comment while considering the context of the meeting so far.\n",
    "Your response should be short , ask questions if needed and keep the discussion open-ended.\n",
    "                                               Also, do not ask too many questions. Think of this discussion as an online team meeting. Give time to others to speak.                                           \n",
    "                                               Do not sound like an email!!!\n",
    "                                               \n",
    "\n",
    "Context : {context}                                          \n",
    "Comment: {query}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "document_chain_SG29 = create_stuff_documents_chain(llm_sg29, prompt_sg29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sg28 = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You are Manager , Data science in Optum. You lead a team of datascientists.\n",
    "You have more than 10 years of experience.\n",
    "You are responsible for data analytics and insights for healthcare industry.                                               \n",
    "You are in a team meeting with other members.\n",
    "Respond to the following comment while considering the context of the meeting so far.\n",
    "Your response should be short , ask questions if needed and keep the discussion open-ended.\n",
    "                                               Also, do not ask too many questions. Think of this discussion as an online team meeting. Give time to others to speak.                                               \n",
    "                                               Do not sound like an email!!!\n",
    "\n",
    "Context : {context}                                          \n",
    "Comment: {query}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "document_chain_SG28 = create_stuff_documents_chain(llm_sg28, prompt_sg28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sg27 = ChatPromptTemplate.from_template(\"\"\"\n",
    "\n",
    "You are Datascientist in Optum. \n",
    "You have 6 years of experience.\n",
    "You are responsible for developing and deploying AI and ML models and testing them.                                              \n",
    "You are in a team meeting with other members.\n",
    "Respond to the following comment while considering the context of the meeting so far.\n",
    "Your response should be short , ask questions if needed and answer all question as asked and try to close them in satisfactory manner.\n",
    "Think of this discussion as an online team meeting. Give time to others to speak.   \n",
    "                                               Do not sound like an email!!!                                            \n",
    "\n",
    "Context : {context}                                          \n",
    "Comment: {query}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "document_chain_SG27 = create_stuff_documents_chain(llm_sg27, prompt_sg27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next person to speak should be SG30, the director of AI engineering. As the meeting has just started, it is appropriate for the director to set the agenda, outline the topics to be discussed, and provide any opening remarks or updates. This will help establish the direction of the meeting and ensure that all participants are aligned on the objectives for the session.\n"
     ]
    }
   ],
   "source": [
    "context  = ''' Hello Everyone, Thanks for joining today'''\n",
    "query = None \n",
    "\n",
    "resp_mod = document_chain_mod.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone, thank you for joining today. As we dive into our agenda, let's focus on our current projects and any challenges we're facing. If anyone has updates or needs assistance, feel free to bring it up. Who would like to start?\n"
     ]
    }
   ],
   "source": [
    "resp_sg30 = document_chain_SG30.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_sg30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG29 should speak next. \n",
      "\n",
      "Since SG30, the director of AI engineering, has opened the floor for updates and challenges, it would be logical for SG29, the lead AI engineer, to speak next. As the lead, SG29 likely has insights into the progress and challenges of the AI projects, making them well-positioned to provide an overview or share any immediate concerns or updates from the engineering team.\n"
     ]
    }
   ],
   "source": [
    "context  = context + f\" SG30: {resp_sg30}\"\n",
    "query = \"SG30\" \n",
    "\n",
    "resp_mod = document_chain_mod.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey team! I'll jump in. We've been working on the predictive analytics model for patient readmission rates. We're hitting some roadblocks with data quality and integration from different sources. Has anyone else faced similar issues, or does anyone have suggestions on how we can better streamline this process?\n"
     ]
    }
   ],
   "source": [
    "context = context \n",
    "query = resp_sg30\n",
    "\n",
    "resp_sg29 = document_chain_SG29.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_sg29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello Everyone, Thanks for joining today SG30: Hello everyone, thank you for joining today. As we dive into our agenda, let's focus on our current projects and any challenges we're facing. If anyone has updates or needs assistance, feel free to bring it up. Who would like to start?\n"
     ]
    }
   ],
   "source": [
    "print(context )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG28 should speak next. As the manager of data science, SG28 likely has experience dealing with data quality and integration challenges and can provide valuable insights or suggestions to help address the issues SG29 mentioned.\n"
     ]
    }
   ],
   "source": [
    "context  = context + f\" SG29: {resp_sg29}\"\n",
    "query = resp_sg29\n",
    "\n",
    "resp_mod = document_chain_mod.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for sharing that update! Data quality and integration can definitely be tricky. We've faced similar challenges in the past. Have we considered implementing a data validation framework to catch issues early? Also, it might be helpful to have a dedicated data integration tool or platform to streamline the process. What do others think?\n"
     ]
    }
   ],
   "source": [
    "context = context \n",
    "query = resp_sg29\n",
    "\n",
    "resp_sg28 = document_chain_SG28.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_sg28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG27 should speak next. Since SG27 is the data scientist or main developer, they are likely to have hands-on experience with data integration and quality issues. They can provide valuable insights or suggestions on implementing a data validation framework or choosing a suitable data integration tool.\n"
     ]
    }
   ],
   "source": [
    "context  = context + f\" SG28: {resp_sg28}\"\n",
    "query = resp_sg28 \n",
    "\n",
    "resp_mod = document_chain_mod.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a great suggestion! Implementing a data validation framework could definitely help us catch issues upfront. In terms of tools, has anyone tried using Talend or Informatica for data integration? They might help streamline things. Also, SG29, could you share more about the specific data sources we're dealing with? That might help us figure out the best approach. Let's hear from others too—what do you think?\n"
     ]
    }
   ],
   "source": [
    "context = context \n",
    "query = resp_sg28\n",
    "\n",
    "resp_sg27 = document_chain_SG27.invoke({\"context\":[Document(page_content=f\"{context}\")], \n",
    "                    \"query\":query})\n",
    "print(resp_sg27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
